{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd1bcc6",
   "metadata": {},
   "source": [
    "**NOTE: For better computing efficiency, I have taken DistilBERT instead of BERT for this POC**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb06f0",
   "metadata": {},
   "source": [
    "### Few Important Links: \n",
    "* Transfer Learning: https://www.hackerearth.com/practice/machine-learning/transfer-learning/transfer-learning-intro/tutorial/\n",
    "* Add class_weights : https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras\n",
    "* Keras Fine-Tuning: https://learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
    "* Huggingface Fine-Tuning: https://huggingface.co/transformers/custom_datasets.html#seq-imdb\n",
    "* Different usages of BERT: https://datascience.stackexchange.com/questions/79772/can-we-use-bert-for-only-word-embedding-and-then-use-svm-rnn-to-do-intent-classi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b5ede",
   "metadata": {},
   "source": [
    "## Classification Problem: Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f36e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline, DistilBertTokenizerFast, TFDistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e90efd",
   "metadata": {},
   "source": [
    "#### Load the moodel and its tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e306a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_19', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc6e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af3d80",
   "metadata": {},
   "source": [
    "### Load and Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cd75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.read_csv('spam.csv')[['v1','v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbde58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['target'] = np.where(mydata['v1']=='ham',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e971a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.drop(columns=['v1'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d778dfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  v2  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                      Ok lar... Joking wif u oni...       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2459897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX, trainY, testY = train_test_split(mydata['v2'],mydata['target'],stratify=mydata['target'],test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8d5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.reset_index(inplace=True,drop=True)\n",
    "testX.reset_index(inplace=True,drop=True)\n",
    "trainY.reset_index(inplace=True,drop=True)\n",
    "testY.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128039a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3900,), (3900,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d86c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validX, testX, validY, testY = train_test_split(testX,testY,stratify=testY,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db25561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validX.reset_index(inplace=True,drop=True)\n",
    "testX.reset_index(inplace=True,drop=True)\n",
    "validY.reset_index(inplace=True,drop=True)\n",
    "testY.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7035617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1337,), (1337,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validX.shape,validY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5269fe71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((335,), (335,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee619ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_max_length=221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a91c92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_encoded = tokenizer(trainX.to_list(),padding='max_length',truncation=True,max_length=my_max_length)\n",
    "validX_encoded = tokenizer(validX.to_list(),padding='max_length',truncation=True,max_length=my_max_length)\n",
    "testX_encoded = tokenizer(testX.to_list(),padding='max_length',truncation=True,max_length=my_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e0de87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=221, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e83ee376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=221, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validX_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffec449e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=221, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29a4c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[trainY==1].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7aec18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2008,\n",
       " 2015,\n",
       " 4658,\n",
       " 1012,\n",
       " 2073,\n",
       " 2323,\n",
       " 1045,\n",
       " 13988,\n",
       " 1029,\n",
       " 2006,\n",
       " 2017,\n",
       " 2030,\n",
       " 1999,\n",
       " 2017,\n",
       " 1029,\n",
       " 1024,\n",
       " 1007,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_encoded['input_ids'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b08c64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(trainX_encoded),trainY))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((dict(validX_encoded),validY))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(testX_encoded),testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7045c330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'input_ids': array([  101,  4658,  1012,  2061,  2129,  2272,  2017,  4033,  2102,\n",
       "           2042,  4511,  2094,  1998, 11586,  2098,  2077,  1029,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0], dtype=int32),\n",
       "   'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0], dtype=int32)},\n",
       "  0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## as_numpy_iterator = > Returns an iterator which converts all elements of the dataset to numpy.\n",
    "\n",
    "list(train_dataset.as_numpy_iterator())[10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c2f12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for element in train_dataset.shuffle(1000).batch(10):\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44066523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a985598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd7d71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1986c6a",
   "metadata": {},
   "source": [
    "### Case1: Use the DistilBERT model as it is to retrain it on the custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7c3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1= model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb77a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model1.compile(optimizer=optimizer, \n",
    "              loss=model.compute_loss) # can also use any keras loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a3001f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "distilbert (TFDistilBertMain multiple                  66362880  \n",
      "_________________________________________________________________\n",
      "pre_classifier (Dense)       multiple                  590592    \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4dccebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 2070s 34s/step - loss: 0.1893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe59ed6ff90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## When you use batch with the dataset, you don't need to define the batch_size in the fit method\n",
    "## source: https://stackoverflow.com/questions/62670041/batch-size-in-tf-model-fit-vs-batch-size-in-tf-data-dataset\n",
    "\n",
    "model1.fit(np.array(trainX_encoded['input_ids']),np.array(trainY), epochs=1, \n",
    "          #validation_data=(np.array(validX_encoded['input_ids']),np.array(validY)),\n",
    "          #validation_split=.2,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb0d88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred = model.predict(testX_encoded['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f5cb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = tf.math.softmax(raw_pred[0], axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92828d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966283524904214"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(testY,pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31710b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55827bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c568b1",
   "metadata": {},
   "source": [
    "### Case2: Add a new dense trainable layer and train this complete model on the custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea5d193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c13763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 221)]             0         \n",
      "_________________________________________________________________\n",
      "tf_distil_bert_for_sequence_ TFSequenceClassifierOutpu 66955010  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 66,957,059\n",
      "Trainable params: 66,957,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape = (221,), dtype='int64')\n",
    "distbert = model2(input_layer)\n",
    "distbert = distbert[0]              \n",
    "flat = tf.keras.layers.Flatten()(distbert)\n",
    "dense = tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu)(flat) # Adding Additional Linear Layer\n",
    "classifier = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid)(dense)\n",
    "mymodel = tf.keras.Model(inputs=input_layer, outputs=classifier)\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdb29efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "mymodel.compile(optimizer=optimizer, \n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics = tf.keras.metrics.AUC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddd5accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 2570s 42s/step - loss: 0.3516 - auc_1: 0.9759 - val_loss: 0.1781 - val_auc_1: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2af301e10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.fit(np.array(trainX_encoded['input_ids']),\n",
    "            np.array(trainY), \n",
    "            epochs=1, \n",
    "            batch_size=64,\n",
    "            validation_data=(np.array(validX_encoded['input_ids']),np.array(validY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26948ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = mymodel.predict(np.array(testX_encoded['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55140ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766283524904215"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(testY,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499cecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32073a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bf141ef",
   "metadata": {},
   "source": [
    "### Case3: Freeze the pretrained model and train only the newly added dense layer on the custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cd43b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2940333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.trainable = False ## Make the training of the model as false, i.e. train only additional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "064f1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 221)]             0         \n",
      "_________________________________________________________________\n",
      "tf_distil_bert_for_sequence_ TFSequenceClassifierOutpu 66955010  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 66,957,059\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 66,955,010\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape = (221,), dtype='int64')\n",
    "distbert = model3(input_layer)\n",
    "distbert = distbert[0]              \n",
    "flat = tf.keras.layers.Flatten()(distbert)\n",
    "dense = tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu)(flat) # Adding Additional Linear Layer\n",
    "classifier = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid)(dense)\n",
    "mymodel = tf.keras.Model(inputs=input_layer, outputs=classifier)\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808af2b",
   "metadata": {},
   "source": [
    "* Here we can see, only 2,049 params are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b86ac143",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "mymodel.compile(optimizer=optimizer, \n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics = tf.keras.metrics.AUC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b09a8491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "61/61 [==============================] - 851s 14s/step - loss: 0.3718 - auc_2: 0.9657 - val_loss: 0.2748 - val_auc_2: 0.9803\n",
      "Epoch 2/3\n",
      "61/61 [==============================] - 845s 14s/step - loss: 0.2391 - auc_2: 0.9643 - val_loss: 0.1980 - val_auc_2: 0.9859\n",
      "Epoch 3/3\n",
      "61/61 [==============================] - 1435s 24s/step - loss: 0.1892 - auc_2: 0.9671 - val_loss: 0.1651 - val_auc_2: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe285427590>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.fit(np.array(trainX_encoded['input_ids']),\n",
    "            np.array(trainY), epochs=3, \n",
    "            batch_size=64,\n",
    "            validation_data=(np.array(validX_encoded['input_ids']),np.array(validY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0e31d611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fd2c07bea90>,\n",
       " <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification at 0x7fd5ae628190>,\n",
       " <keras.layers.core.Flatten at 0x7fd2c07beb50>,\n",
       " <keras.layers.core.Dense at 0x7fd2c05a6c90>,\n",
       " <keras.layers.core.Dense at 0x7fd2a9a06b50>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87e948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38ab41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = mymodel.predict(np.array(testX_encoded['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30799fd",
   "metadata": {},
   "source": [
    "* The closer pred_proba is to 0.0 the more likely it is class 0 and when it is closer to 1.0 then it is more likely that it is class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "760a1b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9781609195402299"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(testY,pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc6e2c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03280e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
