{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from string import punctuation\n",
    "import gensim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/manpreetsi/My Python Jupyter Notebook'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5985   , -0.46321  ,  0.13001  , -0.019576 ,  0.4603   ,\n",
       "       -0.3018   ,  0.8977   , -0.65634  ,  0.66858  , -0.49164  ,\n",
       "        0.037557 , -0.050889 ,  0.6451   , -0.53882  , -0.3765   ,\n",
       "       -0.04312  ,  0.51384  ,  0.17783  ,  0.28596  ,  0.92063  ,\n",
       "       -0.49349  , -0.48583  ,  0.61321  ,  0.78211  ,  0.19254  ,\n",
       "        0.91228  , -0.055596 , -0.12512  , -0.65688  ,  0.068557 ,\n",
       "        0.55629  ,  1.611    , -0.0073642, -0.48879  ,  0.45493  ,\n",
       "        0.96105  , -0.063369 ,  0.17432  ,  0.9814   , -1.3125   ,\n",
       "       -0.15801  , -0.54301  , -0.13888  , -0.26146  , -0.3691   ,\n",
       "        0.26844  , -0.24375  , -0.19484  ,  0.62583  , -0.7377   ,\n",
       "        0.38351  , -0.75004  , -0.39053  ,  0.091498 , -0.36591  ,\n",
       "       -1.4715   , -0.45228  ,  0.2256   ,  1.1412   , -0.38526  ,\n",
       "       -0.06716  ,  0.57288  , -0.39191  ,  0.31302  , -0.29235  ,\n",
       "       -0.96157  ,  0.15154  , -0.21659  ,  0.25103  ,  0.096967 ,\n",
       "        0.2843   ,  1.4296   , -0.50565  , -0.51374  , -0.47218  ,\n",
       "        0.32036  ,  0.023149 ,  0.22623  , -0.09725  ,  0.82126  ,\n",
       "        0.92599  , -1.0086   , -0.38639  ,  0.86408  , -1.206    ,\n",
       "       -0.28528  ,  0.2265   , -0.38773  ,  0.40879  ,  0.59303  ,\n",
       "        0.30769  ,  0.83804  , -0.63655  , -0.44639  , -0.43406  ,\n",
       "       -0.79364  , -0.28675  , -0.034398 ,  1.3431   ,  0.34904  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2291  ,  0.10335 , -0.26987 ,  0.48226 ,  0.33361 ,  0.23705 ,\n",
       "        0.63042 ,  0.43053 ,  0.5771  , -0.52647 , -0.60073 ,  0.23436 ,\n",
       "        0.51035 ,  0.15328 ,  0.38902 ,  0.70331 ,  1.1031  ,  0.2827  ,\n",
       "        0.65623 ,  1.0383  , -0.036059,  0.3269  ,  0.92031 ,  0.12273 ,\n",
       "        0.48289 ,  1.7486  ,  0.57833 , -0.44843 , -0.36878 , -0.58252 ,\n",
       "       -0.25886 ,  0.37798 ,  0.50073 , -0.24892 , -0.38156 ,  0.72429 ,\n",
       "        0.18912 ,  0.35381 ,  0.76222 , -0.83072 ,  0.37245 , -0.74036 ,\n",
       "       -0.093917, -0.19363 ,  0.76738 ,  0.25973 , -0.3613  ,  0.11266 ,\n",
       "        0.074644, -0.50861 , -0.656   , -0.64469 , -0.26661 ,  0.33047 ,\n",
       "       -0.47061 ,  0.10678 , -0.27091 ,  0.74263 , -0.021164, -0.036004,\n",
       "       -0.40231 ,  0.79084 , -0.22085 ,  0.22727 , -0.18947 , -0.89136 ,\n",
       "       -0.20937 , -0.83009 ,  0.431   , -0.30165 ,  0.045189,  0.79236 ,\n",
       "       -0.067395, -0.62576 , -0.10222 ,  0.36835 , -0.29499 , -0.090253,\n",
       "        0.1337  ,  0.77281 ,  0.68425 , -0.66911 ,  0.021237,  0.60893 ,\n",
       "        0.28008 , -0.23189 , -0.55592 , -0.12488 ,  0.44999 ,  0.19754 ,\n",
       "       -0.014878, -0.059546, -1.2438  , -0.30277 , -0.4091  , -0.8396  ,\n",
       "       -0.080137, -0.62914 ,  0.53652 ,  0.17449 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['mango']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63857234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.similarity('canada','ontario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer', 0.7141730785369873),\n",
       " ('computational', 0.7098971009254456),\n",
       " ('software', 0.7074766159057617),\n",
       " ('technology', 0.7047896981239319),\n",
       " ('networking', 0.7002713680267334),\n",
       " ('desktop', 0.6805328726768494),\n",
       " ('automation', 0.6773476004600525),\n",
       " ('computation', 0.6757926344871521),\n",
       " ('applications', 0.6627570986747742),\n",
       " ('systems', 0.6609983444213867)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.most_similar('computing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import spam-ham data to build word2vec RandomForest Ml Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.tsv',header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={0:'target',1:'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim exsiting function to clean the data and tokenize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text']=data['text'].apply(lambda x : gensim.utils.simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>[ve, been, searching, for, the, right, words, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>[have, date, on, sunday, with, will]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text  \\\n",
       "0    ham  I've been searching for the right words to tha...   \n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3    ham  Even my brother is not like to speak with me. ...   \n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [ve, been, searching, for, the, right, words, ...  \n",
       "1  [free, entry, in, wkly, comp, to, win, fa, cup...  \n",
       "2  [nah, don, think, he, goes, to, usf, he, lives...  \n",
       "3  [even, my, brother, is, not, like, to, speak, ...  \n",
       "4               [have, date, on, sunday, with, will]  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target']=data['target'].apply(lambda x : 1 if x=='spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>[ve, been, searching, for, the, right, words, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  I've been searching for the right words to tha...   \n",
       "1       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [ve, been, searching, for, the, right, words, ...  \n",
       "1  [free, entry, in, wkly, comp, to, win, fa, cup...  \n",
       "2  [nah, don, think, he, goes, to, usf, he, lives...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(data['clean_text'],data['target'],test_size=.2,stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=True,inplace=True)\n",
    "x_test.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3857\n",
       "1     597\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4454,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, good, morning, mr, hows, london, treati...\n",
       "1                              [ok, coming, home, now]\n",
       "2    [message, from, am, at, truro, hospital, on, e...\n",
       "3    [lol, have, to, take, it, member, how, said, m...\n",
       "4    [lol, yep, did, that, yesterday, already, got,...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'good', 'morning', 'mr', 'hows', 'london', 'treatin', 'ya', 'treacle']\n"
     ]
    }
   ],
   "source": [
    "print(x_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train.iloc[0])) ## 9 words in 1st sentence of x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Word2Vec model on our data x_train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input is a list of sentences (tokenized)\n",
    "\n",
    "w2v_model= gensim.models.Word2Vec(sentences = x_train,min_count=2,size=300,window=7,sg=0) \n",
    "# sg =0 means CBOW is used ; default sg=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3378, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3378"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vocab) ## learned 3378 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all', 0.9999812245368958),\n",
       " ('but', 0.9999806880950928),\n",
       " ('so', 0.9999781847000122),\n",
       " ('not', 0.9999781847000122),\n",
       " ('in', 0.9999779462814331),\n",
       " ('got', 0.9999778270721436),\n",
       " ('and', 0.999977707862854),\n",
       " ('my', 0.9999772310256958),\n",
       " ('some', 0.999977171421051),\n",
       " ('amp', 0.9999770522117615)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similar_by_word('well') ## words similar to 'too' from our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47207382, -0.13961108,  0.27765065, -0.25325432,  0.14577982,\n",
       "        0.35287786,  0.2802804 ,  0.08277294, -0.18996426, -0.15296431,\n",
       "       -0.38923594, -0.09188627,  0.24426636, -0.00168727, -0.08301775,\n",
       "       -0.12685046,  0.08343118,  0.19974256,  0.09419371, -0.02815917,\n",
       "       -0.00897433,  0.08922294, -0.13551353, -0.15928565,  0.05580015,\n",
       "        0.37857947, -0.08890714, -0.16501957,  0.16081181, -0.10731183,\n",
       "       -0.33358616, -0.16204563,  0.00571158, -0.23911788, -0.04284785,\n",
       "        0.08892088, -0.00520516, -0.05372594,  0.37675884,  0.203797  ,\n",
       "       -0.17920554, -0.2007101 , -0.33767042,  0.27864558,  0.13575162,\n",
       "       -0.41893944,  0.09700918, -0.34902534, -0.05929133,  0.4353584 ,\n",
       "       -0.14796029,  0.49525717,  0.07391249, -0.11671714, -0.32324737,\n",
       "        0.00063345,  0.40168667,  0.32498425, -0.09303671,  0.22008744,\n",
       "        0.25034335,  0.06815549,  0.06212088, -0.12369293, -0.2962859 ,\n",
       "        0.454941  , -0.12425042,  0.0013265 ,  0.1356045 ,  0.04147357,\n",
       "        0.08389471, -0.18387333,  0.26495713, -0.12808096,  0.18993221,\n",
       "        0.055482  , -0.05139101, -0.11004165,  0.2615297 , -0.20446622,\n",
       "       -0.17403421,  0.28247574,  0.10765505,  0.10476793,  0.05135141,\n",
       "       -0.40399036,  0.15313244,  0.07313412, -0.22551782,  0.2733946 ,\n",
       "        0.26857948, -0.11862673, -0.13739282,  0.28230095, -0.06030178,\n",
       "        0.08911617,  0.07288069,  0.04642497,  0.22519785, -0.09918017,\n",
       "        0.41656697,  0.13848376, -0.16943288,  0.06696083, -0.07233935,\n",
       "        0.04570521, -0.02856123, -0.5437838 , -0.16024019, -0.31277364,\n",
       "       -0.0341643 , -0.10166436, -0.46307978,  0.04992541,  0.13963458,\n",
       "       -0.26029092,  0.08136655,  0.21111402,  0.130717  ,  0.07101188,\n",
       "       -0.26296413, -0.17790714,  0.00789008,  0.1828363 ,  0.1242855 ,\n",
       "        0.07703719,  0.15388945,  0.29936206, -0.03396567,  0.0820126 ,\n",
       "       -0.12026524, -0.01356374, -0.14996397, -0.03510512, -0.5417918 ,\n",
       "        0.05956214, -0.07916494,  0.18496199, -0.11667033,  0.20919585,\n",
       "        0.01925805,  0.20251755, -0.19106586,  0.00207634,  0.08867904,\n",
       "        0.10254537, -0.16394733,  0.49041513,  0.17611429,  0.16025908,\n",
       "        0.20750698,  0.42572185,  0.02274858, -0.0050031 , -0.28281415,\n",
       "        0.02792827, -0.34125116,  0.08942899, -0.00519983,  0.25979087,\n",
       "        0.24491124,  0.08126663, -0.13625793, -0.27305758, -0.22070333,\n",
       "        0.21237114, -0.24650848,  0.30485815, -0.00621036, -0.00886213,\n",
       "       -0.32411745,  0.04304976, -0.33936542,  0.11074935,  0.14907764,\n",
       "       -0.14021575,  0.1058138 , -0.12400329, -0.06735624, -0.18782315,\n",
       "       -0.11490697,  0.36864787,  0.06259719, -0.18730831, -0.01886223,\n",
       "       -0.15131842, -0.23886785, -0.25940767, -0.01818539,  0.08391231,\n",
       "        0.18369403,  0.13797544, -0.20336623,  0.18163405, -0.15973212,\n",
       "       -0.04581332,  0.02543677,  0.24584363, -0.10645144, -0.07936191,\n",
       "        0.29324085,  0.42184988, -0.0968641 , -0.04200377,  0.16744512,\n",
       "       -0.12792015, -0.30356693, -0.11570465,  0.08679498,  0.05641316,\n",
       "       -0.06291739,  0.13434438, -0.29467335, -0.21012965, -0.45979246,\n",
       "        0.39787596, -0.20526518, -0.11645071,  0.3797483 , -0.01256065,\n",
       "       -0.22497217, -0.22045425,  0.01197781,  0.40864483, -0.07750091,\n",
       "        0.17679557,  0.08154328, -0.36143053,  0.01023679,  0.40860546,\n",
       "        0.01301546,  0.12073817, -0.1203558 , -0.07716572,  0.13906482,\n",
       "       -0.05555855,  0.03147711, -0.00499396, -0.05932053, -0.2753037 ,\n",
       "       -0.44635695,  0.3987938 ,  0.03802093, -0.10334443,  0.43405598,\n",
       "       -0.09471423, -0.07783714,  0.13201696,  0.18234299,  0.05100071,\n",
       "        0.059643  , -0.05207371,  0.08309788,  0.10455845, -0.07759048,\n",
       "       -0.17009978, -0.24686451,  0.02939012,  0.18418984, -0.04852523,\n",
       "        0.0243744 , -0.02978772,  0.05494014, -0.16155496,  0.0619668 ,\n",
       "       -0.06644558, -0.04455677, -0.33086324,  0.12347662, -0.24021673,\n",
       "       -0.03395293, -0.30957308,  0.45150068,  0.58820516,  0.10190371,\n",
       "       -0.41992074,  0.0688301 ,  0.1013196 ,  0.13569474,  0.09807628,\n",
       "       -0.16188012,  0.25969034, -0.09213544, -0.5053759 , -0.31986883,\n",
       "        0.13704552,  0.05500791, -0.15284003,  0.48030752,  0.18035084,\n",
       "       -0.17911379,  0.06062565,  0.10246337,  0.08672222,  0.13436556,\n",
       "       -0.07545712, -0.30151042, -0.20821226,  0.2062172 ,  0.32293993],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['well'] ## vector representation of 1st word in 1st sentence = 'too'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033620102"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(w2v_model.wv['well']) ## mean value of word 'well' vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting each word in x_train and x_test to its vector representation learned from w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x_train\n",
    "\n",
    "x_train_vect = np.array([ np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vect.size ## This is equal to number of sentences (rows) in x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x_test\n",
    "\n",
    "x_test_vect = np.array([ np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vect.size ## This is equal to number of sentences (rows) in x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_vect[0]) ## Model learnt 7 words out of 9 words in 1st sentence of x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47207382, -0.13961108,  0.27765065, -0.25325432,  0.14577982,\n",
       "        0.35287786,  0.2802804 ,  0.08277294, -0.18996426, -0.15296431,\n",
       "       -0.38923594, -0.09188627,  0.24426636, -0.00168727, -0.08301775,\n",
       "       -0.12685046,  0.08343118,  0.19974256,  0.09419371, -0.02815917,\n",
       "       -0.00897433,  0.08922294, -0.13551353, -0.15928565,  0.05580015,\n",
       "        0.37857947, -0.08890714, -0.16501957,  0.16081181, -0.10731183,\n",
       "       -0.33358616, -0.16204563,  0.00571158, -0.23911788, -0.04284785,\n",
       "        0.08892088, -0.00520516, -0.05372594,  0.37675884,  0.203797  ,\n",
       "       -0.17920554, -0.2007101 , -0.33767042,  0.27864558,  0.13575162,\n",
       "       -0.41893944,  0.09700918, -0.34902534, -0.05929133,  0.4353584 ,\n",
       "       -0.14796029,  0.49525717,  0.07391249, -0.11671714, -0.32324737,\n",
       "        0.00063345,  0.40168667,  0.32498425, -0.09303671,  0.22008744,\n",
       "        0.25034335,  0.06815549,  0.06212088, -0.12369293, -0.2962859 ,\n",
       "        0.454941  , -0.12425042,  0.0013265 ,  0.1356045 ,  0.04147357,\n",
       "        0.08389471, -0.18387333,  0.26495713, -0.12808096,  0.18993221,\n",
       "        0.055482  , -0.05139101, -0.11004165,  0.2615297 , -0.20446622,\n",
       "       -0.17403421,  0.28247574,  0.10765505,  0.10476793,  0.05135141,\n",
       "       -0.40399036,  0.15313244,  0.07313412, -0.22551782,  0.2733946 ,\n",
       "        0.26857948, -0.11862673, -0.13739282,  0.28230095, -0.06030178,\n",
       "        0.08911617,  0.07288069,  0.04642497,  0.22519785, -0.09918017,\n",
       "        0.41656697,  0.13848376, -0.16943288,  0.06696083, -0.07233935,\n",
       "        0.04570521, -0.02856123, -0.5437838 , -0.16024019, -0.31277364,\n",
       "       -0.0341643 , -0.10166436, -0.46307978,  0.04992541,  0.13963458,\n",
       "       -0.26029092,  0.08136655,  0.21111402,  0.130717  ,  0.07101188,\n",
       "       -0.26296413, -0.17790714,  0.00789008,  0.1828363 ,  0.1242855 ,\n",
       "        0.07703719,  0.15388945,  0.29936206, -0.03396567,  0.0820126 ,\n",
       "       -0.12026524, -0.01356374, -0.14996397, -0.03510512, -0.5417918 ,\n",
       "        0.05956214, -0.07916494,  0.18496199, -0.11667033,  0.20919585,\n",
       "        0.01925805,  0.20251755, -0.19106586,  0.00207634,  0.08867904,\n",
       "        0.10254537, -0.16394733,  0.49041513,  0.17611429,  0.16025908,\n",
       "        0.20750698,  0.42572185,  0.02274858, -0.0050031 , -0.28281415,\n",
       "        0.02792827, -0.34125116,  0.08942899, -0.00519983,  0.25979087,\n",
       "        0.24491124,  0.08126663, -0.13625793, -0.27305758, -0.22070333,\n",
       "        0.21237114, -0.24650848,  0.30485815, -0.00621036, -0.00886213,\n",
       "       -0.32411745,  0.04304976, -0.33936542,  0.11074935,  0.14907764,\n",
       "       -0.14021575,  0.1058138 , -0.12400329, -0.06735624, -0.18782315,\n",
       "       -0.11490697,  0.36864787,  0.06259719, -0.18730831, -0.01886223,\n",
       "       -0.15131842, -0.23886785, -0.25940767, -0.01818539,  0.08391231,\n",
       "        0.18369403,  0.13797544, -0.20336623,  0.18163405, -0.15973212,\n",
       "       -0.04581332,  0.02543677,  0.24584363, -0.10645144, -0.07936191,\n",
       "        0.29324085,  0.42184988, -0.0968641 , -0.04200377,  0.16744512,\n",
       "       -0.12792015, -0.30356693, -0.11570465,  0.08679498,  0.05641316,\n",
       "       -0.06291739,  0.13434438, -0.29467335, -0.21012965, -0.45979246,\n",
       "        0.39787596, -0.20526518, -0.11645071,  0.3797483 , -0.01256065,\n",
       "       -0.22497217, -0.22045425,  0.01197781,  0.40864483, -0.07750091,\n",
       "        0.17679557,  0.08154328, -0.36143053,  0.01023679,  0.40860546,\n",
       "        0.01301546,  0.12073817, -0.1203558 , -0.07716572,  0.13906482,\n",
       "       -0.05555855,  0.03147711, -0.00499396, -0.05932053, -0.2753037 ,\n",
       "       -0.44635695,  0.3987938 ,  0.03802093, -0.10334443,  0.43405598,\n",
       "       -0.09471423, -0.07783714,  0.13201696,  0.18234299,  0.05100071,\n",
       "        0.059643  , -0.05207371,  0.08309788,  0.10455845, -0.07759048,\n",
       "       -0.17009978, -0.24686451,  0.02939012,  0.18418984, -0.04852523,\n",
       "        0.0243744 , -0.02978772,  0.05494014, -0.16155496,  0.0619668 ,\n",
       "       -0.06644558, -0.04455677, -0.33086324,  0.12347662, -0.24021673,\n",
       "       -0.03395293, -0.30957308,  0.45150068,  0.58820516,  0.10190371,\n",
       "       -0.41992074,  0.0688301 ,  0.1013196 ,  0.13569474,  0.09807628,\n",
       "       -0.16188012,  0.25969034, -0.09213544, -0.5053759 , -0.31986883,\n",
       "        0.13704552,  0.05500791, -0.15284003,  0.48030752,  0.18035084,\n",
       "       -0.17911379,  0.06062565,  0.10246337,  0.08672222,  0.13436556,\n",
       "       -0.07545712, -0.30151042, -0.20821226,  0.2062172 ,  0.32293993],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vect[0][0] ## Vector representation of 1st word 'well'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average of all the vectors in A is B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representation of each word in 1st sentence in x_train  --- A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47207382, -0.13961108,  0.27765065, ..., -0.20821226,\n",
       "         0.2062172 ,  0.32293993],\n",
       "       [-0.5827319 , -0.17569594,  0.34360495, ..., -0.25637046,\n",
       "         0.25724363,  0.40173388],\n",
       "       [-0.31146488, -0.09337773,  0.18458582, ..., -0.13767523,\n",
       "         0.135458  ,  0.21555294],\n",
       "       ...,\n",
       "       [-0.15100725, -0.04451773,  0.08841141, ..., -0.06793901,\n",
       "         0.06764171,  0.10566685],\n",
       "       [-0.05761864, -0.01659412,  0.03306207, ..., -0.0266624 ,\n",
       "         0.02599317,  0.04070001],\n",
       "       [-0.3197871 , -0.09415666,  0.18703167, ..., -0.13980697,\n",
       "         0.13952878,  0.21894592]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vect[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average vector representation of 1st sentence of x_train ---B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28544715, -0.08514708,  0.16795339, -0.15310659,  0.08834615,\n",
       "        0.2134764 ,  0.17101133,  0.04903498, -0.11560898, -0.09197844,\n",
       "       -0.23734532, -0.05588515,  0.14779124, -0.00102337, -0.04979344,\n",
       "       -0.07829582,  0.05250305,  0.11996113,  0.05710137, -0.01699188,\n",
       "       -0.00598269,  0.05468474, -0.08180215, -0.09657615,  0.03460512,\n",
       "        0.22984275, -0.05466522, -0.10065023,  0.09735962, -0.06497046,\n",
       "       -0.20189078, -0.09746213,  0.00378774, -0.14462355, -0.02626701,\n",
       "        0.0543437 , -0.00391591, -0.03136469,  0.22855099,  0.12303463,\n",
       "       -0.10895541, -0.12110186, -0.20507777,  0.16906823,  0.08255047,\n",
       "       -0.25452536,  0.05845978, -0.212147  , -0.0361036 ,  0.26433584,\n",
       "       -0.09003551,  0.30009618,  0.0445773 , -0.07019343, -0.19632722,\n",
       "        0.00059195,  0.24318512,  0.19674762, -0.0556645 ,  0.13335897,\n",
       "        0.15165234,  0.04123702,  0.03756768, -0.0740245 , -0.17953202,\n",
       "        0.27620628, -0.0754468 ,  0.00082327,  0.08181147,  0.02502135,\n",
       "        0.05133197, -0.11051349,  0.16057444, -0.07820901,  0.1158287 ,\n",
       "        0.03410068, -0.03140396, -0.06657746,  0.15759273, -0.12430054,\n",
       "       -0.10549919,  0.17147212,  0.06442637,  0.0639045 ,  0.03035302,\n",
       "       -0.24498762,  0.09256206,  0.04439793, -0.13616893,  0.16574416,\n",
       "        0.16291608, -0.07063872, -0.08223008,  0.17130484, -0.03733676,\n",
       "        0.05440672,  0.04466073,  0.02803346,  0.1367761 , -0.0612228 ,\n",
       "        0.25265136,  0.08388329, -0.10165329,  0.04054242, -0.04311648,\n",
       "        0.0269074 , -0.01772892, -0.33001423, -0.09796049, -0.19033183,\n",
       "       -0.02026693, -0.0628307 , -0.28042477,  0.0303139 ,  0.08409054,\n",
       "       -0.1581539 ,  0.049187  ,  0.12761416,  0.07942463,  0.04315079,\n",
       "       -0.15911849, -0.10854071,  0.00507922,  0.10966553,  0.07482789,\n",
       "        0.04712075,  0.09329832,  0.18253605, -0.02089212,  0.04980797,\n",
       "       -0.07217087, -0.00846322, -0.09152899, -0.02072757, -0.32779828,\n",
       "        0.03532315, -0.04718023,  0.111558  , -0.06982921,  0.12769641,\n",
       "        0.01246025,  0.12243132, -0.11560763,  0.00121501,  0.05445849,\n",
       "        0.06254531, -0.0997789 ,  0.29737133,  0.10661737,  0.0969177 ,\n",
       "        0.12581512,  0.25767082,  0.01415924, -0.00325188, -0.17225492,\n",
       "        0.01790605, -0.2069972 ,  0.05381482, -0.00224714,  0.15748395,\n",
       "        0.14933121,  0.0501922 , -0.08281579, -0.16545992, -0.13342278,\n",
       "        0.12936439, -0.15058054,  0.18510322, -0.00339542, -0.00560632,\n",
       "       -0.1960799 ,  0.02574503, -0.20598717,  0.06745882,  0.09086848,\n",
       "       -0.08380563,  0.06466553, -0.07570096, -0.04071881, -0.11421634,\n",
       "       -0.07071579,  0.22366837,  0.03675332, -0.11431774, -0.01120885,\n",
       "       -0.09270362, -0.14453731, -0.15721539, -0.01186318,  0.04978337,\n",
       "        0.11238094,  0.08324586, -0.12430838,  0.1105728 , -0.09711279,\n",
       "       -0.02751138,  0.0151805 ,  0.1478859 , -0.06575457, -0.04782395,\n",
       "        0.17755468,  0.25622615, -0.05796135, -0.02460346,  0.10218644,\n",
       "       -0.077939  , -0.1833882 , -0.07114991,  0.05259972,  0.03424688,\n",
       "       -0.03785186,  0.08254402, -0.17852823, -0.12675488, -0.27931973,\n",
       "        0.24167167, -0.12353964, -0.07020687,  0.23184058, -0.0080341 ,\n",
       "       -0.13606371, -0.13443044,  0.00682994,  0.24938817, -0.04621526,\n",
       "        0.10594945,  0.05043442, -0.21917923,  0.00589547,  0.24830835,\n",
       "        0.00774491,  0.07209723, -0.07313318, -0.04720071,  0.08421673,\n",
       "       -0.03443265,  0.01944377, -0.00255737, -0.03718689, -0.16656074,\n",
       "       -0.26970798,  0.24251118,  0.02303992, -0.06244077,  0.26324567,\n",
       "       -0.05709666, -0.04773143,  0.07985865,  0.10994195,  0.03170147,\n",
       "        0.03689551, -0.03203249,  0.04921728,  0.06294619, -0.0478951 ,\n",
       "       -0.10256327, -0.14961123,  0.0180214 ,  0.11225005, -0.02918288,\n",
       "        0.01376794, -0.01816292,  0.03266527, -0.09651136,  0.03707429,\n",
       "       -0.04048464, -0.02661734, -0.20186195,  0.07533059, -0.14636207,\n",
       "       -0.02009876, -0.18717574,  0.2742593 ,  0.35696694,  0.06042397,\n",
       "       -0.25467992,  0.04155826,  0.06082664,  0.08262856,  0.05926222,\n",
       "       -0.09822084,  0.15668726, -0.05559425, -0.30650792, -0.19446805,\n",
       "        0.08368497,  0.03377715, -0.09279934,  0.2910456 ,  0.10945167,\n",
       "       -0.10880415,  0.03791958,  0.06246917,  0.05246416,  0.08165703,\n",
       "       -0.04596436, -0.18297482, -0.12614019,  0.12526648,  0.19668174],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vect[0].mean(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeating the above for all the sentences x_train\n",
    "x_train_vect_avg=[]\n",
    "for v in x_train_vect:\n",
    "    if v.size:\n",
    "        x_train_vect_avg.append(v.mean(axis=0))\n",
    "        \n",
    "    else :\n",
    "        x_train_vect_avg.append(np.zeros(300,dtype=float)) ## 300 as our vector size is 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarly for x_test\n",
    "\n",
    "x_test_vect_avg=[]\n",
    "for v in x_test_vect:\n",
    "    if v.size:\n",
    "        x_test_vect_avg.append(v.mean(axis=0))\n",
    "        \n",
    "    else :\n",
    "        x_test_vect_avg.append(np.zeros(300,dtype=float)) ## 300 as our vector size is 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28544715, -0.08514708,  0.16795339, -0.15310659,  0.08834615,\n",
       "        0.2134764 ,  0.17101133,  0.04903498, -0.11560898, -0.09197844,\n",
       "       -0.23734532, -0.05588515,  0.14779124, -0.00102337, -0.04979344,\n",
       "       -0.07829582,  0.05250305,  0.11996113,  0.05710137, -0.01699188,\n",
       "       -0.00598269,  0.05468474, -0.08180215, -0.09657615,  0.03460512,\n",
       "        0.22984275, -0.05466522, -0.10065023,  0.09735962, -0.06497046,\n",
       "       -0.20189078, -0.09746213,  0.00378774, -0.14462355, -0.02626701,\n",
       "        0.0543437 , -0.00391591, -0.03136469,  0.22855099,  0.12303463,\n",
       "       -0.10895541, -0.12110186, -0.20507777,  0.16906823,  0.08255047,\n",
       "       -0.25452536,  0.05845978, -0.212147  , -0.0361036 ,  0.26433584,\n",
       "       -0.09003551,  0.30009618,  0.0445773 , -0.07019343, -0.19632722,\n",
       "        0.00059195,  0.24318512,  0.19674762, -0.0556645 ,  0.13335897,\n",
       "        0.15165234,  0.04123702,  0.03756768, -0.0740245 , -0.17953202,\n",
       "        0.27620628, -0.0754468 ,  0.00082327,  0.08181147,  0.02502135,\n",
       "        0.05133197, -0.11051349,  0.16057444, -0.07820901,  0.1158287 ,\n",
       "        0.03410068, -0.03140396, -0.06657746,  0.15759273, -0.12430054,\n",
       "       -0.10549919,  0.17147212,  0.06442637,  0.0639045 ,  0.03035302,\n",
       "       -0.24498762,  0.09256206,  0.04439793, -0.13616893,  0.16574416,\n",
       "        0.16291608, -0.07063872, -0.08223008,  0.17130484, -0.03733676,\n",
       "        0.05440672,  0.04466073,  0.02803346,  0.1367761 , -0.0612228 ,\n",
       "        0.25265136,  0.08388329, -0.10165329,  0.04054242, -0.04311648,\n",
       "        0.0269074 , -0.01772892, -0.33001423, -0.09796049, -0.19033183,\n",
       "       -0.02026693, -0.0628307 , -0.28042477,  0.0303139 ,  0.08409054,\n",
       "       -0.1581539 ,  0.049187  ,  0.12761416,  0.07942463,  0.04315079,\n",
       "       -0.15911849, -0.10854071,  0.00507922,  0.10966553,  0.07482789,\n",
       "        0.04712075,  0.09329832,  0.18253605, -0.02089212,  0.04980797,\n",
       "       -0.07217087, -0.00846322, -0.09152899, -0.02072757, -0.32779828,\n",
       "        0.03532315, -0.04718023,  0.111558  , -0.06982921,  0.12769641,\n",
       "        0.01246025,  0.12243132, -0.11560763,  0.00121501,  0.05445849,\n",
       "        0.06254531, -0.0997789 ,  0.29737133,  0.10661737,  0.0969177 ,\n",
       "        0.12581512,  0.25767082,  0.01415924, -0.00325188, -0.17225492,\n",
       "        0.01790605, -0.2069972 ,  0.05381482, -0.00224714,  0.15748395,\n",
       "        0.14933121,  0.0501922 , -0.08281579, -0.16545992, -0.13342278,\n",
       "        0.12936439, -0.15058054,  0.18510322, -0.00339542, -0.00560632,\n",
       "       -0.1960799 ,  0.02574503, -0.20598717,  0.06745882,  0.09086848,\n",
       "       -0.08380563,  0.06466553, -0.07570096, -0.04071881, -0.11421634,\n",
       "       -0.07071579,  0.22366837,  0.03675332, -0.11431774, -0.01120885,\n",
       "       -0.09270362, -0.14453731, -0.15721539, -0.01186318,  0.04978337,\n",
       "        0.11238094,  0.08324586, -0.12430838,  0.1105728 , -0.09711279,\n",
       "       -0.02751138,  0.0151805 ,  0.1478859 , -0.06575457, -0.04782395,\n",
       "        0.17755468,  0.25622615, -0.05796135, -0.02460346,  0.10218644,\n",
       "       -0.077939  , -0.1833882 , -0.07114991,  0.05259972,  0.03424688,\n",
       "       -0.03785186,  0.08254402, -0.17852823, -0.12675488, -0.27931973,\n",
       "        0.24167167, -0.12353964, -0.07020687,  0.23184058, -0.0080341 ,\n",
       "       -0.13606371, -0.13443044,  0.00682994,  0.24938817, -0.04621526,\n",
       "        0.10594945,  0.05043442, -0.21917923,  0.00589547,  0.24830835,\n",
       "        0.00774491,  0.07209723, -0.07313318, -0.04720071,  0.08421673,\n",
       "       -0.03443265,  0.01944377, -0.00255737, -0.03718689, -0.16656074,\n",
       "       -0.26970798,  0.24251118,  0.02303992, -0.06244077,  0.26324567,\n",
       "       -0.05709666, -0.04773143,  0.07985865,  0.10994195,  0.03170147,\n",
       "        0.03689551, -0.03203249,  0.04921728,  0.06294619, -0.0478951 ,\n",
       "       -0.10256327, -0.14961123,  0.0180214 ,  0.11225005, -0.02918288,\n",
       "        0.01376794, -0.01816292,  0.03266527, -0.09651136,  0.03707429,\n",
       "       -0.04048464, -0.02661734, -0.20186195,  0.07533059, -0.14636207,\n",
       "       -0.02009876, -0.18717574,  0.2742593 ,  0.35696694,  0.06042397,\n",
       "       -0.25467992,  0.04155826,  0.06082664,  0.08262856,  0.05926222,\n",
       "       -0.09822084,  0.15668726, -0.05559425, -0.30650792, -0.19446805,\n",
       "        0.08368497,  0.03377715, -0.09279934,  0.2910456 ,  0.10945167,\n",
       "       -0.10880415,  0.03791958,  0.06246917,  0.05246416,  0.08165703,\n",
       "       -0.04596436, -0.18297482, -0.12614019,  0.12526648,  0.19668174],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vect_avg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.285447</td>\n",
       "      <td>-0.085147</td>\n",
       "      <td>0.167953</td>\n",
       "      <td>-0.153107</td>\n",
       "      <td>0.088346</td>\n",
       "      <td>0.213476</td>\n",
       "      <td>0.171011</td>\n",
       "      <td>0.049035</td>\n",
       "      <td>-0.115609</td>\n",
       "      <td>-0.091978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108804</td>\n",
       "      <td>0.037920</td>\n",
       "      <td>0.062469</td>\n",
       "      <td>0.052464</td>\n",
       "      <td>0.081657</td>\n",
       "      <td>-0.045964</td>\n",
       "      <td>-0.182975</td>\n",
       "      <td>-0.126140</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>0.196682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.454783</td>\n",
       "      <td>-0.137820</td>\n",
       "      <td>0.266681</td>\n",
       "      <td>-0.244636</td>\n",
       "      <td>0.142640</td>\n",
       "      <td>0.342708</td>\n",
       "      <td>0.271581</td>\n",
       "      <td>0.077881</td>\n",
       "      <td>-0.184442</td>\n",
       "      <td>-0.146046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173348</td>\n",
       "      <td>0.059022</td>\n",
       "      <td>0.101876</td>\n",
       "      <td>0.083718</td>\n",
       "      <td>0.129473</td>\n",
       "      <td>-0.071964</td>\n",
       "      <td>-0.290660</td>\n",
       "      <td>-0.203664</td>\n",
       "      <td>0.201978</td>\n",
       "      <td>0.313183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.555876</td>\n",
       "      <td>-0.167705</td>\n",
       "      <td>0.325787</td>\n",
       "      <td>-0.298167</td>\n",
       "      <td>0.174247</td>\n",
       "      <td>0.418107</td>\n",
       "      <td>0.332186</td>\n",
       "      <td>0.096436</td>\n",
       "      <td>-0.224113</td>\n",
       "      <td>-0.178390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212661</td>\n",
       "      <td>0.073758</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>0.102570</td>\n",
       "      <td>0.157233</td>\n",
       "      <td>-0.087633</td>\n",
       "      <td>-0.353896</td>\n",
       "      <td>-0.247947</td>\n",
       "      <td>0.244861</td>\n",
       "      <td>0.382215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.453674</td>\n",
       "      <td>-0.136456</td>\n",
       "      <td>0.266455</td>\n",
       "      <td>-0.243204</td>\n",
       "      <td>0.141939</td>\n",
       "      <td>0.341049</td>\n",
       "      <td>0.271295</td>\n",
       "      <td>0.078219</td>\n",
       "      <td>-0.184077</td>\n",
       "      <td>-0.145612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173513</td>\n",
       "      <td>0.059718</td>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.083234</td>\n",
       "      <td>0.128707</td>\n",
       "      <td>-0.071806</td>\n",
       "      <td>-0.289492</td>\n",
       "      <td>-0.202279</td>\n",
       "      <td>0.200115</td>\n",
       "      <td>0.311621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.486376</td>\n",
       "      <td>-0.146208</td>\n",
       "      <td>0.284847</td>\n",
       "      <td>-0.260903</td>\n",
       "      <td>0.151723</td>\n",
       "      <td>0.364885</td>\n",
       "      <td>0.289858</td>\n",
       "      <td>0.084232</td>\n",
       "      <td>-0.196398</td>\n",
       "      <td>-0.156451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186302</td>\n",
       "      <td>0.064367</td>\n",
       "      <td>0.106321</td>\n",
       "      <td>0.089678</td>\n",
       "      <td>0.138068</td>\n",
       "      <td>-0.077314</td>\n",
       "      <td>-0.310168</td>\n",
       "      <td>-0.216781</td>\n",
       "      <td>0.214579</td>\n",
       "      <td>0.334667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>-0.464023</td>\n",
       "      <td>-0.140099</td>\n",
       "      <td>0.271963</td>\n",
       "      <td>-0.248990</td>\n",
       "      <td>0.145639</td>\n",
       "      <td>0.350104</td>\n",
       "      <td>0.277118</td>\n",
       "      <td>0.080219</td>\n",
       "      <td>-0.188928</td>\n",
       "      <td>-0.150591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177963</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.102707</td>\n",
       "      <td>0.085062</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>-0.074056</td>\n",
       "      <td>-0.296907</td>\n",
       "      <td>-0.207500</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.318532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>-0.428814</td>\n",
       "      <td>-0.129200</td>\n",
       "      <td>0.252255</td>\n",
       "      <td>-0.229954</td>\n",
       "      <td>0.134660</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.256012</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>-0.173004</td>\n",
       "      <td>-0.137952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164002</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>0.079061</td>\n",
       "      <td>0.121503</td>\n",
       "      <td>-0.067749</td>\n",
       "      <td>-0.273286</td>\n",
       "      <td>-0.190995</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.293766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>-0.474483</td>\n",
       "      <td>-0.142924</td>\n",
       "      <td>0.278490</td>\n",
       "      <td>-0.254528</td>\n",
       "      <td>0.148612</td>\n",
       "      <td>0.357215</td>\n",
       "      <td>0.283854</td>\n",
       "      <td>0.082219</td>\n",
       "      <td>-0.192106</td>\n",
       "      <td>-0.153081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181031</td>\n",
       "      <td>0.063041</td>\n",
       "      <td>0.103879</td>\n",
       "      <td>0.086834</td>\n",
       "      <td>0.135042</td>\n",
       "      <td>-0.074759</td>\n",
       "      <td>-0.302454</td>\n",
       "      <td>-0.211506</td>\n",
       "      <td>0.209002</td>\n",
       "      <td>0.326035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>-0.402770</td>\n",
       "      <td>-0.121327</td>\n",
       "      <td>0.236315</td>\n",
       "      <td>-0.216030</td>\n",
       "      <td>0.125794</td>\n",
       "      <td>0.303071</td>\n",
       "      <td>0.240351</td>\n",
       "      <td>0.069884</td>\n",
       "      <td>-0.162530</td>\n",
       "      <td>-0.129857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.052955</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.074399</td>\n",
       "      <td>0.114195</td>\n",
       "      <td>-0.064327</td>\n",
       "      <td>-0.257389</td>\n",
       "      <td>-0.178937</td>\n",
       "      <td>0.177597</td>\n",
       "      <td>0.277044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>-0.447035</td>\n",
       "      <td>-0.134028</td>\n",
       "      <td>0.261422</td>\n",
       "      <td>-0.239604</td>\n",
       "      <td>0.140915</td>\n",
       "      <td>0.337106</td>\n",
       "      <td>0.267381</td>\n",
       "      <td>0.077458</td>\n",
       "      <td>-0.180831</td>\n",
       "      <td>-0.143979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170165</td>\n",
       "      <td>0.057953</td>\n",
       "      <td>0.100104</td>\n",
       "      <td>0.083505</td>\n",
       "      <td>0.126281</td>\n",
       "      <td>-0.069575</td>\n",
       "      <td>-0.283294</td>\n",
       "      <td>-0.200713</td>\n",
       "      <td>0.196392</td>\n",
       "      <td>0.308457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4454 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.285447 -0.085147  0.167953 -0.153107  0.088346  0.213476  0.171011   \n",
       "1    -0.454783 -0.137820  0.266681 -0.244636  0.142640  0.342708  0.271581   \n",
       "2    -0.555876 -0.167705  0.325787 -0.298167  0.174247  0.418107  0.332186   \n",
       "3    -0.453674 -0.136456  0.266455 -0.243204  0.141939  0.341049  0.271295   \n",
       "4    -0.486376 -0.146208  0.284847 -0.260903  0.151723  0.364885  0.289858   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4449 -0.464023 -0.140099  0.271963 -0.248990  0.145639  0.350104  0.277118   \n",
       "4450 -0.428814 -0.129200  0.252255 -0.229954  0.134660  0.322350  0.256012   \n",
       "4451 -0.474483 -0.142924  0.278490 -0.254528  0.148612  0.357215  0.283854   \n",
       "4452 -0.402770 -0.121327  0.236315 -0.216030  0.125794  0.303071  0.240351   \n",
       "4453 -0.447035 -0.134028  0.261422 -0.239604  0.140915  0.337106  0.267381   \n",
       "\n",
       "           7         8         9    ...       290       291       292  \\\n",
       "0     0.049035 -0.115609 -0.091978  ... -0.108804  0.037920  0.062469   \n",
       "1     0.077881 -0.184442 -0.146046  ... -0.173348  0.059022  0.101876   \n",
       "2     0.096436 -0.224113 -0.178390  ... -0.212661  0.073758  0.121491   \n",
       "3     0.078219 -0.184077 -0.145612  ... -0.173513  0.059718  0.099020   \n",
       "4     0.084232 -0.196398 -0.156451  ... -0.186302  0.064367  0.106321   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4449  0.080219 -0.188928 -0.150591  ... -0.177963  0.060818  0.102707   \n",
       "4450  0.074051 -0.173004 -0.137952  ... -0.164002  0.056816  0.093425   \n",
       "4451  0.082219 -0.192106 -0.153081  ... -0.181031  0.063041  0.103879   \n",
       "4452  0.069884 -0.162530 -0.129857  ... -0.155332  0.052955  0.088889   \n",
       "4453  0.077458 -0.180831 -0.143979  ... -0.170165  0.057953  0.100104   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "0     0.052464  0.081657 -0.045964 -0.182975 -0.126140  0.125266  0.196682  \n",
       "1     0.083718  0.129473 -0.071964 -0.290660 -0.203664  0.201978  0.313183  \n",
       "2     0.102570  0.157233 -0.087633 -0.353896 -0.247947  0.244861  0.382215  \n",
       "3     0.083234  0.128707 -0.071806 -0.289492 -0.202279  0.200115  0.311621  \n",
       "4     0.089678  0.138068 -0.077314 -0.310168 -0.216781  0.214579  0.334667  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4449  0.085062  0.132376 -0.074056 -0.296907 -0.207500  0.206143  0.318532  \n",
       "4450  0.079061  0.121503 -0.067749 -0.273286 -0.190995  0.189757  0.293766  \n",
       "4451  0.086834  0.135042 -0.074759 -0.302454 -0.211506  0.209002  0.326035  \n",
       "4452  0.074399  0.114195 -0.064327 -0.257389 -0.178937  0.177597  0.277044  \n",
       "4453  0.083505  0.126281 -0.069575 -0.283294 -0.200713  0.196392  0.308457  \n",
       "\n",
       "[4454 rows x 300 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500,max_depth=100,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(x_train_vect_avg,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = rf_model.predict_proba(x_test_vect_avg)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_model.predict(x_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663594950794588"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_proba) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8992248062015504"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785234899328859"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
