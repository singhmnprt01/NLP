{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f70f68",
   "metadata": {},
   "source": [
    "## Neural Machine Translation (German to English)\n",
    "**LSTM Encoder-Decoder Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69325d50",
   "metadata": {},
   "source": [
    "A typical seq2seq model has 2 major components:\n",
    "* a) an encoder\n",
    "* b) a decoder\n",
    "\n",
    "Use cases of Sequence-to-Sequence: \n",
    "* Speech Recognition\n",
    "* Name Entity/Subject Extraction to identify the main subject from a body of text\n",
    "* Relation Classification to tag relationships between various entities tagged in the above step\n",
    "* Chatbot skills to have conversational ability and engage with customers\n",
    "* Text Summarization to generate a concise summary of a large amount of text\n",
    "* Question Answering systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf4500",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://miro.medium.com/max/2400/1*sWc8g2yiQrOzntbVeGzbEQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "618d32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, Input, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth',200)\n",
    "pd.set_option('display.max_rows',2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ec86e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/manprmas/Oracle Content - Accounts/Oracle Content/Personal/Advanced NLP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee093e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('deu.txt',mode='rt',encoding='utf-8')\n",
    "data = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b64599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.strip().split('\\n')\n",
    "data_sents = [i.split('\\t') for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5865f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = np.array(data_sents)\n",
    "deu_eng = deu_eng[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93039d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Geh.'],\n",
       "       ['Hi.', 'Hallo!'],\n",
       "       ['Hi.', 'Grüß Gott!'],\n",
       "       ['Run!', 'Lauf!'],\n",
       "       ['Run.', 'Lauf!'],\n",
       "       ['Wow!', 'Potzdonner!'],\n",
       "       ['Wow!', 'Donnerwetter!'],\n",
       "       ['Duck!', 'Kopf runter!'],\n",
       "       ['Fire!', 'Feuer!'],\n",
       "       ['Help!', 'Hilfe!']], dtype='<U537')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3fa6d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3170c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "981b944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Geh'],\n",
       "       ['Hi', 'Hallo'],\n",
       "       ['Hi', 'Grüß Gott'],\n",
       "       ['Run', 'Lauf'],\n",
       "       ['Run', 'Lauf'],\n",
       "       ['Wow', 'Potzdonner'],\n",
       "       ['Wow', 'Donnerwetter'],\n",
       "       ['Duck', 'Kopf runter'],\n",
       "       ['Fire', 'Feuer'],\n",
       "       ['Help', 'Hilfe']], dtype='<U537')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e45ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(deu_eng.shape[0], size=100000, replace=False)\n",
    "deu_eng = deu_eng[random_indices, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78079061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d918b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321a726d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['i have a lot of questions', 'ich habe zahlreiche fragen'],\n",
       "       ['tom and mary are house hunting',\n",
       "        'tom und mary sind auf der suche nach einem haus'],\n",
       "       ['theyre engaged', 'sie sind verlobt'],\n",
       "       ['tom is intolerant', 'tom ist intolerant'],\n",
       "       ['as soon as he went to bed he fell asleep',\n",
       "        'sobald er ins bett ging schlief er ein'],\n",
       "       ['you have a very good voice', 'du hast eine sehr gute stimme'],\n",
       "       ['i want to leave too', 'ich möchte auch gehen'],\n",
       "       ['tom and mary were held as hostages for three months',\n",
       "        'tom und mary waren drei monate in geiselhaft'],\n",
       "       ['did you enjoy your swim', 'hat dir das schwimmen spaß gemacht'],\n",
       "       ['knock before entering', 'klopfe an bevor du hereinkommst']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a3d0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00fb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d6bece9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 12006\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e7dc031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tom': 1,\n",
       " 'to': 2,\n",
       " 'you': 3,\n",
       " 'the': 4,\n",
       " 'i': 5,\n",
       " 'a': 6,\n",
       " 'is': 7,\n",
       " 'that': 8,\n",
       " 'in': 9,\n",
       " 'do': 10,\n",
       " 'he': 11,\n",
       " 'of': 12,\n",
       " 'it': 13,\n",
       " 'was': 14,\n",
       " 'this': 15,\n",
       " 'have': 16,\n",
       " 'me': 17,\n",
       " 'dont': 18,\n",
       " 'for': 19,\n",
       " 'my': 20,\n",
       " 'what': 21,\n",
       " 'are': 22,\n",
       " 'mary': 23,\n",
       " 'we': 24,\n",
       " 'your': 25,\n",
       " 'his': 26,\n",
       " 'be': 27,\n",
       " 'im': 28,\n",
       " 'and': 29,\n",
       " 'on': 30,\n",
       " 'with': 31,\n",
       " 'know': 32,\n",
       " 'want': 33,\n",
       " 'like': 34,\n",
       " 'not': 35,\n",
       " 'she': 36,\n",
       " 'at': 37,\n",
       " 'did': 38,\n",
       " 'has': 39,\n",
       " 'can': 40,\n",
       " 'how': 41,\n",
       " 'very': 42,\n",
       " 'were': 43,\n",
       " 'here': 44,\n",
       " 'go': 45,\n",
       " 'didnt': 46,\n",
       " 'think': 47,\n",
       " 'as': 48,\n",
       " 'its': 49,\n",
       " 'about': 50,\n",
       " 'there': 51,\n",
       " 'him': 52,\n",
       " 'cant': 53,\n",
       " 'will': 54,\n",
       " 'time': 55,\n",
       " 'all': 56,\n",
       " 'up': 57,\n",
       " 'why': 58,\n",
       " 'youre': 59,\n",
       " 'had': 60,\n",
       " 'if': 61,\n",
       " 'get': 62,\n",
       " 'going': 63,\n",
       " 'they': 64,\n",
       " 'her': 65,\n",
       " 'good': 66,\n",
       " 'one': 67,\n",
       " 'isnt': 68,\n",
       " 'out': 69,\n",
       " 'no': 70,\n",
       " 'really': 71,\n",
       " 'when': 72,\n",
       " 'from': 73,\n",
       " 'doesnt': 74,\n",
       " 'would': 75,\n",
       " 'an': 76,\n",
       " 'ill': 77,\n",
       " 'now': 78,\n",
       " 'by': 79,\n",
       " 'been': 80,\n",
       " 'help': 81,\n",
       " 'please': 82,\n",
       " 'come': 83,\n",
       " 'just': 84,\n",
       " 'need': 85,\n",
       " 'who': 86,\n",
       " 'never': 87,\n",
       " 'see': 88,\n",
       " 'us': 89,\n",
       " 'toms': 90,\n",
       " 'where': 91,\n",
       " 'tell': 92,\n",
       " 'french': 93,\n",
       " 'said': 94,\n",
       " 'too': 95,\n",
       " 'got': 96,\n",
       " 'than': 97,\n",
       " 'so': 98,\n",
       " 'ive': 99,\n",
       " 'more': 100,\n",
       " 'take': 101,\n",
       " 'much': 102,\n",
       " 'could': 103,\n",
       " 'but': 104,\n",
       " 'boston': 105,\n",
       " 'should': 106,\n",
       " 'thats': 107,\n",
       " 'home': 108,\n",
       " 'well': 109,\n",
       " 'some': 110,\n",
       " 'something': 111,\n",
       " 'still': 112,\n",
       " 'money': 113,\n",
       " 'work': 114,\n",
       " 'car': 115,\n",
       " 'does': 116,\n",
       " 'lot': 117,\n",
       " 'day': 118,\n",
       " 'three': 119,\n",
       " 'back': 120,\n",
       " 'told': 121,\n",
       " 'anything': 122,\n",
       " 'people': 123,\n",
       " 'any': 124,\n",
       " 'many': 125,\n",
       " 'say': 126,\n",
       " 'make': 127,\n",
       " 'always': 128,\n",
       " 'today': 129,\n",
       " 'id': 130,\n",
       " 'room': 131,\n",
       " 'made': 132,\n",
       " 'thought': 133,\n",
       " 'last': 134,\n",
       " 'book': 135,\n",
       " 'doing': 136,\n",
       " 'went': 137,\n",
       " 'long': 138,\n",
       " 'our': 139,\n",
       " 'right': 140,\n",
       " 'only': 141,\n",
       " 'school': 142,\n",
       " 'better': 143,\n",
       " 'house': 144,\n",
       " 'love': 145,\n",
       " 'look': 146,\n",
       " 'again': 147,\n",
       " 'new': 148,\n",
       " 'wasnt': 149,\n",
       " 'am': 150,\n",
       " 'eat': 151,\n",
       " 'talk': 152,\n",
       " 'hes': 153,\n",
       " 'whats': 154,\n",
       " 'asked': 155,\n",
       " 'give': 156,\n",
       " 'into': 157,\n",
       " 'speak': 158,\n",
       " 'ever': 159,\n",
       " 'wont': 160,\n",
       " 'before': 161,\n",
       " 'every': 162,\n",
       " 'tomorrow': 163,\n",
       " 'down': 164,\n",
       " 'off': 165,\n",
       " 'let': 166,\n",
       " 'way': 167,\n",
       " 'leave': 168,\n",
       " 'old': 169,\n",
       " 'over': 170,\n",
       " 'put': 171,\n",
       " 'wanted': 172,\n",
       " 'left': 173,\n",
       " 'sure': 174,\n",
       " 'or': 175,\n",
       " 'happy': 176,\n",
       " 'years': 177,\n",
       " 'must': 178,\n",
       " 'other': 179,\n",
       " 'already': 180,\n",
       " 'everything': 181,\n",
       " 'may': 182,\n",
       " 'lets': 183,\n",
       " 'after': 184,\n",
       " 'knows': 185,\n",
       " 'two': 186,\n",
       " 'man': 187,\n",
       " 'find': 188,\n",
       " 'theres': 189,\n",
       " 'ask': 190,\n",
       " 'dog': 191,\n",
       " 'next': 192,\n",
       " 'night': 193,\n",
       " 'wants': 194,\n",
       " 'came': 195,\n",
       " 'stop': 196,\n",
       " 'father': 197,\n",
       " 'live': 198,\n",
       " 'job': 199,\n",
       " 'little': 200,\n",
       " 'saw': 201,\n",
       " 'these': 202,\n",
       " 'first': 203,\n",
       " 'yesterday': 204,\n",
       " 'stay': 205,\n",
       " 'took': 206,\n",
       " 'read': 207,\n",
       " 'children': 208,\n",
       " 'done': 209,\n",
       " 'nothing': 210,\n",
       " 'call': 211,\n",
       " 'understand': 212,\n",
       " 'buy': 213,\n",
       " 'looking': 214,\n",
       " 'friends': 215,\n",
       " 'teacher': 216,\n",
       " 'play': 217,\n",
       " 'arent': 218,\n",
       " 'name': 219,\n",
       " 'hard': 220,\n",
       " 'away': 221,\n",
       " 'often': 222,\n",
       " 'problem': 223,\n",
       " 'late': 224,\n",
       " 'used': 225,\n",
       " 'couldnt': 226,\n",
       " 'happened': 227,\n",
       " 'wait': 228,\n",
       " 'without': 229,\n",
       " 'enough': 230,\n",
       " 'wrong': 231,\n",
       " 'soon': 232,\n",
       " 'things': 233,\n",
       " 'lost': 234,\n",
       " 'keep': 235,\n",
       " 'believe': 236,\n",
       " 'busy': 237,\n",
       " 'try': 238,\n",
       " 'almost': 239,\n",
       " 'them': 240,\n",
       " 'hope': 241,\n",
       " 'life': 242,\n",
       " 'gave': 243,\n",
       " 'door': 244,\n",
       " 'alone': 245,\n",
       " 'youve': 246,\n",
       " 'morning': 247,\n",
       " 'their': 248,\n",
       " 'likes': 249,\n",
       " 'feel': 250,\n",
       " 'yet': 251,\n",
       " 'week': 252,\n",
       " 'mother': 253,\n",
       " 'australia': 254,\n",
       " 'even': 255,\n",
       " 'everyone': 256,\n",
       " 'bad': 257,\n",
       " 'heard': 258,\n",
       " 'water': 259,\n",
       " 'marys': 260,\n",
       " 'seen': 261,\n",
       " 'knew': 262,\n",
       " 'remember': 263,\n",
       " 'bought': 264,\n",
       " 'cold': 265,\n",
       " 'friend': 266,\n",
       " 'himself': 267,\n",
       " 'question': 268,\n",
       " 'married': 269,\n",
       " 'looks': 270,\n",
       " 'english': 271,\n",
       " 'anymore': 272,\n",
       " 'thing': 273,\n",
       " 'hear': 274,\n",
       " 'open': 275,\n",
       " 'found': 276,\n",
       " 'wouldnt': 277,\n",
       " 'youll': 278,\n",
       " 'around': 279,\n",
       " 'each': 280,\n",
       " 'looked': 281,\n",
       " 'train': 282,\n",
       " 'havent': 283,\n",
       " 'else': 284,\n",
       " 'drink': 285,\n",
       " 'best': 286,\n",
       " 'coffee': 287,\n",
       " 'both': 288,\n",
       " 'anyone': 289,\n",
       " 'able': 290,\n",
       " 'getting': 291,\n",
       " 'use': 292,\n",
       " 'wish': 293,\n",
       " 'bus': 294,\n",
       " 'idea': 295,\n",
       " 'being': 296,\n",
       " 'beautiful': 297,\n",
       " 'talking': 298,\n",
       " 'most': 299,\n",
       " 'answer': 300,\n",
       " 'year': 301,\n",
       " 'another': 302,\n",
       " 'big': 303,\n",
       " 'tried': 304,\n",
       " 'same': 305,\n",
       " 'afraid': 306,\n",
       " 'mind': 307,\n",
       " 'someone': 308,\n",
       " 'bed': 309,\n",
       " 'tired': 310,\n",
       " 'days': 311,\n",
       " 'sorry': 312,\n",
       " 'while': 313,\n",
       " 'seems': 314,\n",
       " 'because': 315,\n",
       " 'learn': 316,\n",
       " 'early': 317,\n",
       " 'books': 318,\n",
       " 'parents': 319,\n",
       " 'watch': 320,\n",
       " 'true': 321,\n",
       " 'waiting': 322,\n",
       " 'happen': 323,\n",
       " 'says': 324,\n",
       " 'youd': 325,\n",
       " 'doctor': 326,\n",
       " 'few': 327,\n",
       " 'letter': 328,\n",
       " 'kind': 329,\n",
       " 'person': 330,\n",
       " 'boy': 331,\n",
       " 'theyre': 332,\n",
       " 'working': 333,\n",
       " 'family': 334,\n",
       " 'turn': 335,\n",
       " 'might': 336,\n",
       " 'nice': 337,\n",
       " 'party': 338,\n",
       " 'which': 339,\n",
       " 'food': 340,\n",
       " 'show': 341,\n",
       " 'pretty': 342,\n",
       " 'once': 343,\n",
       " 'pay': 344,\n",
       " 'brother': 345,\n",
       " 'write': 346,\n",
       " 'those': 347,\n",
       " 'coming': 348,\n",
       " 'lives': 349,\n",
       " 'together': 350,\n",
       " 'until': 351,\n",
       " 'hours': 352,\n",
       " 'called': 353,\n",
       " 'probably': 354,\n",
       " 'john': 355,\n",
       " 'matter': 356,\n",
       " 'yourself': 357,\n",
       " 'nobody': 358,\n",
       " 'important': 359,\n",
       " 'sleep': 360,\n",
       " 'young': 361,\n",
       " 'started': 362,\n",
       " 'such': 363,\n",
       " 'care': 364,\n",
       " 'ago': 365,\n",
       " 'accident': 366,\n",
       " 'minutes': 367,\n",
       " 'study': 368,\n",
       " 'phone': 369,\n",
       " 'great': 370,\n",
       " 'fun': 371,\n",
       " 'place': 372,\n",
       " 'walk': 373,\n",
       " 'wonder': 374,\n",
       " 'times': 375,\n",
       " 'needs': 376,\n",
       " 'police': 377,\n",
       " 'girl': 378,\n",
       " 'plan': 379,\n",
       " 'longer': 380,\n",
       " 'meeting': 381,\n",
       " 'window': 382,\n",
       " 'forget': 383,\n",
       " 'shes': 384,\n",
       " 'station': 385,\n",
       " 'hand': 386,\n",
       " 'sister': 387,\n",
       " 'far': 388,\n",
       " 'everybody': 389,\n",
       " 'decided': 390,\n",
       " 'met': 391,\n",
       " 'hair': 392,\n",
       " 'thank': 393,\n",
       " 'cat': 394,\n",
       " 'trying': 395,\n",
       " 'weve': 396,\n",
       " 'died': 397,\n",
       " 'easy': 398,\n",
       " 'world': 399,\n",
       " 'favorite': 400,\n",
       " 'students': 401,\n",
       " 'since': 402,\n",
       " 'truth': 403,\n",
       " 'office': 404,\n",
       " 'ready': 405,\n",
       " 'change': 406,\n",
       " 'difficult': 407,\n",
       " 'reading': 408,\n",
       " 'fell': 409,\n",
       " 'miss': 410,\n",
       " 'hate': 411,\n",
       " 'broke': 412,\n",
       " 'mine': 413,\n",
       " 'table': 414,\n",
       " 'wearing': 415,\n",
       " 'own': 416,\n",
       " 'month': 417,\n",
       " 'mean': 418,\n",
       " 'wife': 419,\n",
       " 'swim': 420,\n",
       " 'fast': 421,\n",
       " 'questions': 422,\n",
       " 'quite': 423,\n",
       " 'sick': 424,\n",
       " 'shouldnt': 425,\n",
       " 'hurt': 426,\n",
       " 'picture': 427,\n",
       " 'hot': 428,\n",
       " 'meet': 429,\n",
       " 'son': 430,\n",
       " 'tv': 431,\n",
       " 'angry': 432,\n",
       " 'usually': 433,\n",
       " 'dinner': 434,\n",
       " 'lunch': 435,\n",
       " 'ate': 436,\n",
       " 'playing': 437,\n",
       " 'sat': 438,\n",
       " 'seem': 439,\n",
       " 'drive': 440,\n",
       " 'word': 441,\n",
       " 'mistake': 442,\n",
       " 'makes': 443,\n",
       " 'finished': 444,\n",
       " 'japan': 445,\n",
       " 'fish': 446,\n",
       " 'ten': 447,\n",
       " 'trouble': 448,\n",
       " 'shouldve': 449,\n",
       " 'gone': 450,\n",
       " 'later': 451,\n",
       " 'myself': 452,\n",
       " 'run': 453,\n",
       " 'movie': 454,\n",
       " 'rain': 455,\n",
       " 'chance': 456,\n",
       " 'city': 457,\n",
       " 'watching': 458,\n",
       " 'turned': 459,\n",
       " 'hungry': 460,\n",
       " 'through': 461,\n",
       " 'goes': 462,\n",
       " 'whos': 463,\n",
       " 'listen': 464,\n",
       " 'park': 465,\n",
       " 'arrived': 466,\n",
       " 'trust': 467,\n",
       " 'saying': 468,\n",
       " 'living': 469,\n",
       " 'stupid': 470,\n",
       " 'monday': 471,\n",
       " 'start': 472,\n",
       " 'eyes': 473,\n",
       " 'ran': 474,\n",
       " 'story': 475,\n",
       " 'town': 476,\n",
       " 'music': 477,\n",
       " 'whether': 478,\n",
       " 'ok': 479,\n",
       " 'become': 480,\n",
       " 'eating': 481,\n",
       " 'shoes': 482,\n",
       " 'fire': 483,\n",
       " 'rich': 484,\n",
       " 'free': 485,\n",
       " 'possible': 486,\n",
       " 'killed': 487,\n",
       " 'glad': 488,\n",
       " 'careful': 489,\n",
       " 'wheres': 490,\n",
       " 'red': 491,\n",
       " 'asleep': 492,\n",
       " 'woman': 493,\n",
       " 'breakfast': 494,\n",
       " 'hands': 495,\n",
       " 'loves': 496,\n",
       " 'thirty': 497,\n",
       " 'small': 498,\n",
       " '230': 499,\n",
       " 'having': 500,\n",
       " 'older': 501,\n",
       " 'hed': 502,\n",
       " 'bicycle': 503,\n",
       " 'street': 504,\n",
       " 'outside': 505,\n",
       " 'front': 506,\n",
       " 'close': 507,\n",
       " 'student': 508,\n",
       " 'under': 509,\n",
       " 'box': 510,\n",
       " 'homework': 511,\n",
       " 'works': 512,\n",
       " 'bit': 513,\n",
       " 'interested': 514,\n",
       " 'stand': 515,\n",
       " 'visit': 516,\n",
       " 'country': 517,\n",
       " 'light': 518,\n",
       " 'surprised': 519,\n",
       " 'lived': 520,\n",
       " 'wine': 521,\n",
       " 'interesting': 522,\n",
       " 'caught': 523,\n",
       " 'maybe': 524,\n",
       " 'making': 525,\n",
       " 'clothes': 526,\n",
       " 'milk': 527,\n",
       " 'expect': 528,\n",
       " 'studying': 529,\n",
       " 'spend': 530,\n",
       " 'walked': 531,\n",
       " 'tea': 532,\n",
       " 'reason': 533,\n",
       " 'daughter': 534,\n",
       " 'river': 535,\n",
       " 'end': 536,\n",
       " 'needed': 537,\n",
       " 'seemed': 538,\n",
       " 'summer': 539,\n",
       " 'hasnt': 540,\n",
       " 'paid': 541,\n",
       " 'changed': 542,\n",
       " 'win': 543,\n",
       " 'behind': 544,\n",
       " 'sit': 545,\n",
       " 'exactly': 546,\n",
       " 'tennis': 547,\n",
       " 'class': 548,\n",
       " 'high': 549,\n",
       " 'news': 550,\n",
       " 'hurry': 551,\n",
       " 'japanese': 552,\n",
       " 'age': 553,\n",
       " 'became': 554,\n",
       " 'speaks': 555,\n",
       " 'spent': 556,\n",
       " 'language': 557,\n",
       " 'quickly': 558,\n",
       " 'cup': 559,\n",
       " 'child': 560,\n",
       " 'then': 561,\n",
       " 'number': 562,\n",
       " 'dress': 563,\n",
       " 'computer': 564,\n",
       " 'felt': 565,\n",
       " 'kept': 566,\n",
       " 'tonight': 567,\n",
       " 'baby': 568,\n",
       " 'yours': 569,\n",
       " 'dark': 570,\n",
       " 'agree': 571,\n",
       " 'thinks': 572,\n",
       " 'snow': 573,\n",
       " 'weather': 574,\n",
       " 'wrote': 575,\n",
       " 'tree': 576,\n",
       " 'lie': 577,\n",
       " 'forgot': 578,\n",
       " 'along': 579,\n",
       " 'game': 580,\n",
       " 'taking': 581,\n",
       " 'birthday': 582,\n",
       " 'black': 583,\n",
       " 'company': 584,\n",
       " 'problems': 585,\n",
       " 'began': 586,\n",
       " 'five': 587,\n",
       " 'cut': 588,\n",
       " 'whose': 589,\n",
       " 'comes': 590,\n",
       " 'hat': 591,\n",
       " 'bring': 592,\n",
       " 'dogs': 593,\n",
       " 'garden': 594,\n",
       " 'afternoon': 595,\n",
       " 'worry': 596,\n",
       " 'gets': 597,\n",
       " 'cannot': 598,\n",
       " 'glasses': 599,\n",
       " 'anybody': 600,\n",
       " 'death': 601,\n",
       " 'advice': 602,\n",
       " 'whole': 603,\n",
       " 'itll': 604,\n",
       " 'eaten': 605,\n",
       " 'moment': 606,\n",
       " 'between': 607,\n",
       " 'men': 608,\n",
       " 'feeling': 609,\n",
       " 'sometimes': 610,\n",
       " 'flowers': 611,\n",
       " 'hit': 612,\n",
       " 'against': 613,\n",
       " 'lose': 614,\n",
       " 'full': 615,\n",
       " 'hour': 616,\n",
       " 'stopped': 617,\n",
       " 'catch': 618,\n",
       " 'worried': 619,\n",
       " 'stayed': 620,\n",
       " 'dead': 621,\n",
       " 'proud': 622,\n",
       " 'near': 623,\n",
       " 'helped': 624,\n",
       " 'finish': 625,\n",
       " 'weekend': 626,\n",
       " 'white': 627,\n",
       " 'song': 628,\n",
       " 'beer': 629,\n",
       " 'order': 630,\n",
       " 'dollars': 631,\n",
       " 'secret': 632,\n",
       " 'thanks': 633,\n",
       " 'promise': 634,\n",
       " 'talked': 635,\n",
       " 'sing': 636,\n",
       " 'drunk': 637,\n",
       " 'swimming': 638,\n",
       " 'hospital': 639,\n",
       " 'piano': 640,\n",
       " 'strange': 641,\n",
       " 'missed': 642,\n",
       " 'clean': 643,\n",
       " 'cost': 644,\n",
       " 'floor': 645,\n",
       " 'wear': 646,\n",
       " 'thinking': 647,\n",
       " 'others': 648,\n",
       " 'guys': 649,\n",
       " 'sense': 650,\n",
       " 'set': 651,\n",
       " 'inside': 652,\n",
       " 'expensive': 653,\n",
       " 'war': 654,\n",
       " 'explain': 655,\n",
       " 'kids': 656,\n",
       " 'born': 657,\n",
       " 'restaurant': 658,\n",
       " 'hotel': 659,\n",
       " 'touch': 660,\n",
       " 'worked': 661,\n",
       " 'across': 662,\n",
       " 'camera': 663,\n",
       " 'decision': 664,\n",
       " 'enjoy': 665,\n",
       " 'real': 666,\n",
       " 'desk': 667,\n",
       " 'bag': 668,\n",
       " 'glass': 669,\n",
       " 'tall': 670,\n",
       " 'seat': 671,\n",
       " 'six': 672,\n",
       " 'library': 673,\n",
       " 'closed': 674,\n",
       " 'serious': 675,\n",
       " 'apple': 676,\n",
       " 'die': 677,\n",
       " 'evening': 678,\n",
       " 'noise': 679,\n",
       " 'dance': 680,\n",
       " 'poor': 681,\n",
       " 'break': 682,\n",
       " 'beach': 683,\n",
       " 'girlfriend': 684,\n",
       " 'worth': 685,\n",
       " 'umbrella': 686,\n",
       " 'played': 687,\n",
       " 'women': 688,\n",
       " 'known': 689,\n",
       " 'head': 690,\n",
       " 'telling': 691,\n",
       " 'pass': 692,\n",
       " 'girls': 693,\n",
       " 'blue': 694,\n",
       " 'move': 695,\n",
       " 'fine': 696,\n",
       " 'opened': 697,\n",
       " 'store': 698,\n",
       " 'dangerous': 699,\n",
       " 'trip': 700,\n",
       " 'return': 701,\n",
       " 'present': 702,\n",
       " 'werent': 703,\n",
       " 'situation': 704,\n",
       " 'mistakes': 705,\n",
       " 'shut': 706,\n",
       " 'completely': 707,\n",
       " 'takes': 708,\n",
       " 'prefer': 709,\n",
       " 'cake': 710,\n",
       " 'sound': 711,\n",
       " 'liked': 712,\n",
       " 'key': 713,\n",
       " 'supposed': 714,\n",
       " 'couple': 715,\n",
       " 'smoking': 716,\n",
       " 'scared': 717,\n",
       " 'half': 718,\n",
       " 'send': 719,\n",
       " 'happens': 720,\n",
       " 'opinion': 721,\n",
       " 'sunday': 722,\n",
       " 'paper': 723,\n",
       " 'several': 724,\n",
       " 'team': 725,\n",
       " 'hardly': 726,\n",
       " 'attention': 727,\n",
       " 'christmas': 728,\n",
       " 'listening': 729,\n",
       " 'large': 730,\n",
       " 'quiet': 731,\n",
       " 'during': 732,\n",
       " 'welcome': 733,\n",
       " 'worse': 734,\n",
       " 'expected': 735,\n",
       " 'short': 736,\n",
       " 'stood': 737,\n",
       " 'showed': 738,\n",
       " 'heart': 739,\n",
       " 'kiss': 740,\n",
       " 'loved': 741,\n",
       " 'months': 742,\n",
       " 'safe': 743,\n",
       " 'speaking': 744,\n",
       " 'lying': 745,\n",
       " 'knife': 746,\n",
       " 'sitting': 747,\n",
       " 'business': 748,\n",
       " 'either': 749,\n",
       " 'side': 750,\n",
       " 'guitar': 751,\n",
       " 'planning': 752,\n",
       " 'face': 753,\n",
       " 'cook': 754,\n",
       " 'different': 755,\n",
       " 'hell': 756,\n",
       " 'rather': 757,\n",
       " 'asking': 758,\n",
       " 'raining': 759,\n",
       " 'written': 760,\n",
       " 'arrive': 761,\n",
       " 'kill': 762,\n",
       " 'four': 763,\n",
       " 'ought': 764,\n",
       " 'choice': 765,\n",
       " 'plane': 766,\n",
       " 'traffic': 767,\n",
       " 'taxi': 768,\n",
       " 'driving': 769,\n",
       " 'dictionary': 770,\n",
       " 'cats': 771,\n",
       " 'kissed': 772,\n",
       " 'oclock': 773,\n",
       " 'broken': 774,\n",
       " 'tokyo': 775,\n",
       " 'ice': 776,\n",
       " 'health': 777,\n",
       " 'sounds': 778,\n",
       " 'second': 779,\n",
       " 'concert': 780,\n",
       " 'bread': 781,\n",
       " 'teach': 782,\n",
       " 'brought': 783,\n",
       " 'finally': 784,\n",
       " 'taken': 785,\n",
       " 'nervous': 786,\n",
       " 'strong': 787,\n",
       " 'building': 788,\n",
       " 'road': 789,\n",
       " 'actually': 790,\n",
       " 'guy': 791,\n",
       " 'quit': 792,\n",
       " 'ship': 793,\n",
       " 'noticed': 794,\n",
       " 'air': 795,\n",
       " 'boys': 796,\n",
       " 'famous': 797,\n",
       " 'guess': 798,\n",
       " 'alive': 799,\n",
       " 'fault': 800,\n",
       " 'sleeping': 801,\n",
       " 'spoke': 802,\n",
       " 'canadian': 803,\n",
       " 'blame': 804,\n",
       " 'college': 805,\n",
       " 'movies': 806,\n",
       " 'pain': 807,\n",
       " 'pick': 808,\n",
       " 'husband': 809,\n",
       " 'past': 810,\n",
       " 'drinking': 811,\n",
       " 'follow': 812,\n",
       " 'message': 813,\n",
       " 'brothers': 814,\n",
       " 'cars': 815,\n",
       " 'promised': 816,\n",
       " 'also': 817,\n",
       " 'danger': 818,\n",
       " 'smoke': 819,\n",
       " 'future': 820,\n",
       " 'rest': 821,\n",
       " 'wall': 822,\n",
       " 'seeing': 823,\n",
       " 'report': 824,\n",
       " 'beginning': 825,\n",
       " 'tie': 826,\n",
       " 'medicine': 827,\n",
       " 'invited': 828,\n",
       " 'plans': 829,\n",
       " 'waited': 830,\n",
       " 'least': 831,\n",
       " 'part': 832,\n",
       " 'somebody': 833,\n",
       " 'bank': 834,\n",
       " 'test': 835,\n",
       " 'leaving': 836,\n",
       " 'solve': 837,\n",
       " 'shot': 838,\n",
       " 'less': 839,\n",
       " 'exam': 840,\n",
       " 'weeks': 841,\n",
       " 'sisters': 842,\n",
       " 'cry': 843,\n",
       " 'travel': 844,\n",
       " 'afford': 845,\n",
       " 'won': 846,\n",
       " 'means': 847,\n",
       " 'abroad': 848,\n",
       " 'translate': 849,\n",
       " 'hold': 850,\n",
       " 'wash': 851,\n",
       " 'empty': 852,\n",
       " 'owe': 853,\n",
       " 'radio': 854,\n",
       " 'carry': 855,\n",
       " 'correct': 856,\n",
       " 'kitchen': 857,\n",
       " 'telephone': 858,\n",
       " 'warm': 859,\n",
       " 'shopping': 860,\n",
       " 'deal': 861,\n",
       " 'funny': 862,\n",
       " 'forward': 863,\n",
       " 'perfect': 864,\n",
       " 'piece': 865,\n",
       " 'success': 866,\n",
       " 'lawyer': 867,\n",
       " 'hadnt': 868,\n",
       " 'given': 869,\n",
       " 'easily': 870,\n",
       " 'seldom': 871,\n",
       " 'crying': 872,\n",
       " 'taught': 873,\n",
       " 'picked': 874,\n",
       " 'check': 875,\n",
       " 'disappointed': 876,\n",
       " 'apologize': 877,\n",
       " 'though': 878,\n",
       " 'heavy': 879,\n",
       " 'running': 880,\n",
       " 'harder': 881,\n",
       " 'somewhere': 882,\n",
       " 'learned': 883,\n",
       " 'fix': 884,\n",
       " 'difference': 885,\n",
       " 'slept': 886,\n",
       " 'choose': 887,\n",
       " 'player': 888,\n",
       " 'sky': 889,\n",
       " 'mountain': 890,\n",
       " 'apples': 891,\n",
       " 'joke': 892,\n",
       " 'point': 893,\n",
       " 'apartment': 894,\n",
       " 'pictures': 895,\n",
       " 'price': 896,\n",
       " 'hates': 897,\n",
       " 'crazy': 898,\n",
       " 'prison': 899,\n",
       " 'winter': 900,\n",
       " 'sad': 901,\n",
       " 'clear': 902,\n",
       " 'allowed': 903,\n",
       " 'rules': 904,\n",
       " 'baseball': 905,\n",
       " 'animals': 906,\n",
       " 'likely': 907,\n",
       " 'twice': 908,\n",
       " 'stolen': 909,\n",
       " 'address': 910,\n",
       " 'horse': 911,\n",
       " 'singing': 912,\n",
       " 'anywhere': 913,\n",
       " 'american': 914,\n",
       " 'lucky': 915,\n",
       " 'begin': 916,\n",
       " 'passed': 917,\n",
       " 'patient': 918,\n",
       " 'plays': 919,\n",
       " 'airport': 920,\n",
       " 'weight': 921,\n",
       " 'shirt': 922,\n",
       " 'truck': 923,\n",
       " 'novel': 924,\n",
       " 'bill': 925,\n",
       " 'confused': 926,\n",
       " 'ones': 927,\n",
       " 'chair': 928,\n",
       " 'sun': 929,\n",
       " 'bottle': 930,\n",
       " 'boss': 931,\n",
       " 'laughed': 932,\n",
       " 'visited': 933,\n",
       " 'america': 934,\n",
       " 'writing': 935,\n",
       " 'lied': 936,\n",
       " 'suit': 937,\n",
       " 'bridge': 938,\n",
       " 'sign': 939,\n",
       " 'arm': 940,\n",
       " 'boyfriend': 941,\n",
       " 'necessary': 942,\n",
       " 'hundred': 943,\n",
       " 'mood': 944,\n",
       " 'sent': 945,\n",
       " 'dream': 946,\n",
       " 'pleased': 947,\n",
       " 'watched': 948,\n",
       " 'church': 949,\n",
       " 'shop': 950,\n",
       " 'save': 951,\n",
       " 'terrible': 952,\n",
       " 'alice': 953,\n",
       " 'october': 954,\n",
       " 'languages': 955,\n",
       " 'bike': 956,\n",
       " 'pizza': 957,\n",
       " 'honest': 958,\n",
       " 'seven': 959,\n",
       " 'rice': 960,\n",
       " 'walking': 961,\n",
       " 'feed': 962,\n",
       " 'younger': 963,\n",
       " 'whatever': 964,\n",
       " 'count': 965,\n",
       " 'smell': 966,\n",
       " 'soccer': 967,\n",
       " 'wears': 968,\n",
       " 'accept': 969,\n",
       " 'dirty': 970,\n",
       " 'suddenly': 971,\n",
       " 'expecting': 972,\n",
       " 'sell': 973,\n",
       " 'answered': 974,\n",
       " 'eggs': 975,\n",
       " 'ticket': 976,\n",
       " 'standing': 977,\n",
       " 'cooking': 978,\n",
       " 'driver': 979,\n",
       " 'meat': 980,\n",
       " 'oil': 981,\n",
       " 'earth': 982,\n",
       " 'voice': 983,\n",
       " 'excuse': 984,\n",
       " 'mom': 985,\n",
       " 'list': 986,\n",
       " 'fruit': 987,\n",
       " 'eats': 988,\n",
       " 'agreed': 989,\n",
       " 'marry': 990,\n",
       " 'keys': 991,\n",
       " 'laugh': 992,\n",
       " 'television': 993,\n",
       " 'fight': 994,\n",
       " 'kid': 995,\n",
       " 'till': 996,\n",
       " 'ball': 997,\n",
       " 'herself': 998,\n",
       " 'doubt': 999,\n",
       " 'line': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "773b8a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 22582\n"
     ]
    }
   ],
   "source": [
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e61d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    \n",
    "    # pad sequences with 0 values\n",
    "    seq = sequence.pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1448ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "92956d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'may i put it here'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb0aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "974ab956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([182,   5, 171,  13,  44,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f57816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c064a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b87857",
   "metadata": {},
   "source": [
    "### RepeatVector vs return_sequences=True\n",
    "\n",
    "![Image of Yaktocat](https://i.stack.imgur.com/LNXjF.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd447d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8113240",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 32)\n",
    "rms = RMSprop(lr=0.01)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "286de475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 32)             722624    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8, 12006)          396198    \n",
      "=================================================================\n",
      "Total params: 1,135,462\n",
      "Trainable params: 1,135,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9777e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_nlp_machine_translation_lstm'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b24e589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 30000 samples\n",
      "69632/70000 [============================>.] - ETA: 3s - loss: 2.6964 \n",
      "Epoch 00001: val_loss improved from 3.32064 to 3.30594, saving model to model_nlp_machine_translation_lstm\n",
      "INFO:tensorflow:Assets written to: model_nlp_machine_translation_lstm/assets\n",
      "70000/70000 [==============================] - 915s 13ms/sample - loss: 2.6966 - val_loss: 3.3059\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=1, batch_size=1024, \n",
    "          validation_data = [testX,testY.reshape(testY.shape[0], testY.shape[1], 1)],\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6efdc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "51c843cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4604175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "461cd84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   7,   7,   2,   2,   2, 105, 105],\n",
       "       [  5,   6,  48,  48,  48,  48,   6,  48],\n",
       "       [ 20, 115,  39, 134, 134,   0,   0,   0],\n",
       "       [ 77,  63,   2,   3,   3,   0,   0,   0],\n",
       "       [  1,   7,  20,  26,  11,  11,  11,   0],\n",
       "       [  5,  53,  35,  48,  48,  48,   0,   0],\n",
       "       [  1, 149, 619,   0,   0,   0,   0,   0],\n",
       "       [  1,  14, 224,   0,   0,   0,   0,   0],\n",
       "       [  3, 174, 174,   3,   3,   3,   0,   0],\n",
       "       [  4,   4,   4, 576,   4,   4,   4, 818]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d073683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8d2136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5dc704d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "350e2d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>im quite hungry</td>\n",
       "      <td>im very hungry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual            predicted\n",
       "45  im quite hungry  im very hungry     "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.iloc[45:46,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a6df8b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ich bin ziemlich hungrig'], dtype='<U537')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[45:46,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d469d61",
   "metadata": {},
   "source": [
    "### Extract Embeddings from Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3f89512",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1d8d231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings = {w:embeddings[idx] for w, idx in eng_tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9ab02ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6456634e-01, -5.1916063e-01, -7.9730794e-02,  1.6115907e-01,\n",
       "       -3.3530605e-01, -3.3116352e-03, -7.4509019e-01,  4.9231246e-02,\n",
       "       -1.9988891e-01,  2.4994239e-01, -2.9379165e-01, -1.7670871e-01,\n",
       "       -5.9266701e-02,  6.8998128e-02, -1.5970820e-01,  1.5919159e-01,\n",
       "       -9.8319747e-02, -2.4200144e-01, -1.7721292e-02,  1.5975747e-01,\n",
       "        6.3015006e-02,  1.6616705e-01,  4.0547571e-01, -2.6260704e-01,\n",
       "        1.0263384e-04, -2.8314281e-01, -2.3600174e-02, -4.0434178e-02,\n",
       "        3.0470502e-01, -1.3632643e-01, -8.1682831e-02, -6.7003801e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_embeddings['quite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a34a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
